{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBvp2oFUoeNGb2j6eUg/o8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grosetta/rdkit_study/blob/main/train_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewf5K0tnqHT_",
        "outputId": "7e28ffd5-0a08-4b06-a576-48c5e6b7c46f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#文件头代码\n",
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "sys.path.insert(0,\"/content/gdrive/My Drive/Colab Notebooks/python_package/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import itertools\n",
        "import operator\n",
        "import numpy as np\n",
        "import nltk\n",
        "import os\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "from IPython import display\n",
        "from rdkit.Chem import Descriptors\n",
        "import sys\n",
        "from datetime import datetime\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation,TimeDistributed\n",
        "from keras.layers import LSTM,GRU\n",
        "from keras.layers import Embedding\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.layers import Dropout\n",
        "import random\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import model_from_json\n",
        "#from make_smile import ziprocess_organic,process_zinc_data\n",
        "#from make_smile import zinc_data_with_bracket_original,zinc_processed_with_bracket\n",
        "from keras.layers import Conv1D, MaxPooling1D"
      ],
      "metadata": {
        "id": "TVzS2kFWqXUW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 函数定义"
      ],
      "metadata": {
        "id": "ouINmz0DrCVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def zinc_data_with_bracket_original():\n",
        "#将文件的所有smile转存为一个列表，列表中每一个元素是一个smile\n",
        "    sen_space=[]\n",
        "    f = open('/content/gdrive/My Drive/data/250k_rndm_zinc_drugs_clean.smi', 'r')\n",
        "\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "        sen_space.append(row) #此时的sen_space是列表里套列表的形式\n",
        "    f.close()\n",
        "\n",
        "    zinc_processed=[]\n",
        "    for i in range(len(sen_space)):\n",
        "        word1=sen_space[i]\n",
        "        zinc_processed.append(word1[0])\n",
        "    return zinc_processed"
      ],
      "metadata": {
        "id": "Z4XpoOsYrEgV"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def zinc_processed_with_bracket(sen_space):\n",
        "    all_smile=[]\n",
        "    length=[]\n",
        "    end=\"\\n\"\n",
        "    element_table=[\"C\",\"N\",\"B\",\"O\",\"P\",\"S\",\"F\",\"Cl\",\"Br\",\"I\",\"(\",\")\",\"=\",\"#\"]\n",
        "    ring=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"]\n",
        "\n",
        "    for i in range(len(sen_space)):\n",
        "        word_space=sen_space[i]\n",
        "        word=[]\n",
        "        j=0\n",
        "        while j<len(word_space):\n",
        "            word_space1=[]\n",
        "            if word_space[j]==\"[\":\n",
        "                word_space1.append(word_space[j])\n",
        "                j=j+1\n",
        "                while word_space[j]!=\"]\":\n",
        "                    word_space1.append(word_space[j])\n",
        "                    j=j+1\n",
        "                word_space1.append(word_space[j])\n",
        "                word_space2=''.join(word_space1)\n",
        "                word.append(word_space2)    #将smile的中括号即其内部的字母作为整体添加到word列表中\n",
        "                j=j+1\n",
        "            else:\n",
        "                word_space1.append(word_space[j])\n",
        "\n",
        "                if j+1<len(word_space):\n",
        "                    word_space1.append(word_space[j+1])  #如果第j个字符不是最后一个，那就继续遍历\n",
        "                    word_space2=''.join(word_space1)\n",
        "                else:\n",
        "                    word_space1.insert(0,word_space[j-1]) #如果第j个字符是最后一个\n",
        "                    word_space2=''.join(word_space1)\n",
        "\n",
        "                if word_space2 not in element_table:   #如果第j个字符不在预定的元素集合里，就照搬到word列表中 \n",
        "                    word.append(word_space[j])\n",
        "                    j=j+1\n",
        "                else:\n",
        "                    word.append(word_space2)\n",
        "                    j=j+2\n",
        "\n",
        "\n",
        "        word.append(end)  #给每个列表元素最后加终止符\n",
        "        word.insert(0,\"&\") #给每个列表第一个元素前加&\n",
        "        len1=len(word)\n",
        "        length.append(len1) #每个元素（smile各字符隔开）长度添加到一个列表中，和all_smile中一一对应。\n",
        "        all_smile.append(list(word))\n",
        "    val=[\"\\n\"]\n",
        "    for i in range(len(all_smile)):\n",
        "        for j in range(len(all_smile[i])):   #j的取值范围各不相同，受制于各smile长度\n",
        "            if all_smile[i][j] not in val:\n",
        "                val.append(all_smile[i][j])\n",
        "\n",
        "    return val, all_smile"
      ],
      "metadata": {
        "id": "qCjyOrjMsDF9"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 代码主体"
      ],
      "metadata": {
        "id": "Qm1Gp2-LrEym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smile=zinc_data_with_bracket_original()\n",
        "valcabulary,all_smile=zinc_processed_with_bracket(smile)\n",
        "print(valcabulary)\n",
        "print(len(all_smile))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4FNd04prG11",
        "outputId": "3f7f93ca-6c71-4678-fd83-8f070f9df9e0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', '&', 'C', '(', ')', 'c', '1', '2', 'o', '=', 'O', 'N', '3', 'F', '[C@@H]', 'n', '-', '#', 'S', 'Cl', '[O-]', '[C@H]', '[NH+]', '[C@]', 's', 'Br', '/', '[nH]', '[NH3+]', '4', '[NH2+]', '[C@@]', '[N+]', '[nH+]', '\\\\', '[S@]', '5', '[N-]', '[n+]', '[S@@]', '[S-]', '6', '7', 'I', '[n-]', 'P', '[OH+]', '[NH-]', '[P@@H]', '[P@@]', '[PH2]', '[P@]', '[P+]', '[S+]', '[o+]', '[CH2-]', '[CH-]', '[SH+]', '[O+]', '[s+]', '[PH+]', '[PH]', '8', '[S@@+]']\n",
            "249456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smile"
      ],
      "metadata": {
        "id": "iX48CF76vM6q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}